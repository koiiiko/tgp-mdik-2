{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82c5d42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0ac9f7",
   "metadata": {},
   "source": [
    "Superstore pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "816875fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark = SparkSession.builder \\\n",
    "#     .appName(\"DeltaLake\") \\\n",
    "#     .master(\"local[*]\") \\\n",
    "#     .config(\"spark.jars.packages\", \n",
    "#             \"org.apache.spark:spark-sql-kafka-0-10_2.13:4.0.0,io.delta:delta-spark_2.13:4.0.0\") \\\n",
    "#     .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "#     .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "#     .getOrCreate()\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DeltaLake with Hive Integration\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.jars.packages\", \n",
    "            \"org.apache.spark:spark-sql-kafka-0-10_2.13:4.0.0,io.delta:delta-spark_2.13:4.0.0\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"hive\") \\\n",
    "    .config(\"spark.python.worker.timeout\", \"1200\") \\\n",
    "    .config(\"spark.network.timeout\", \"1200s\") \\\n",
    "    .config(\"spark.executor.heartbeatInterval\", \"60s\") \\\n",
    "    .config(\"spark.python.worker.reuse\", \"true\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"false\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "df_superstore = spark.read.format(\"delta\").load(\"hdfs://localhost:9000/delta_superstore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09cd7216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9936\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|message                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|{'Row ID': '1', 'Order ID': 'CA-2016-152156', 'Order Date': '11/8/2016', 'Ship Date': '11/11/2016', 'Ship Mode': 'Second Class', 'Customer ID': 'CG-12520', 'Customer Name': 'Claire Gute', 'Segment': 'Consumer', 'Country': 'United States', 'City': 'Henderson', 'State': 'Kentucky', 'Postal Code': '42420', 'Region': 'South', 'Product ID': 'FUR-BO-10001798', 'Category': 'Furniture', 'Sub-Category': 'Bookcases', 'Product Name': 'Bush Somerset Collection Bookcase', 'Sales': '261.96', 'Quantity': '2', 'Discount': '0', 'Profit': '41.9136'}                                |\n",
      "|{'Row ID': '2', 'Order ID': 'CA-2016-152156', 'Order Date': '11/8/2016', 'Ship Date': '11/11/2016', 'Ship Mode': 'Second Class', 'Customer ID': 'CG-12520', 'Customer Name': 'Claire Gute', 'Segment': 'Consumer', 'Country': 'United States', 'City': 'Henderson', 'State': 'Kentucky', 'Postal Code': '42420', 'Region': 'South', 'Product ID': 'FUR-CH-10000454', 'Category': 'Furniture', 'Sub-Category': 'Chairs', 'Product Name': 'Hon Deluxe Fabric Upholstered Stacking Chairs, Rounded Back', 'Sales': '731.94', 'Quantity': '3', 'Discount': '0', 'Profit': '219.582'}         |\n",
      "|{'Row ID': '3', 'Order ID': 'CA-2016-138688', 'Order Date': '6/12/2016', 'Ship Date': '6/16/2016', 'Ship Mode': 'Second Class', 'Customer ID': 'DV-13045', 'Customer Name': 'Darrin Van Huff', 'Segment': 'Corporate', 'Country': 'United States', 'City': 'Los Angeles', 'State': 'California', 'Postal Code': '90036', 'Region': 'West', 'Product ID': 'OFF-LA-10000240', 'Category': 'Office Supplies', 'Sub-Category': 'Labels', 'Product Name': 'Self-Adhesive Address Labels for Typewriters by Universal', 'Sales': '14.62', 'Quantity': '2', 'Discount': '0', 'Profit': '6.8714'}|\n",
      "|{'Row ID': '4', 'Order ID': 'US-2015-108966', 'Order Date': '10/11/2015', 'Ship Date': '10/18/2015', 'Ship Mode': 'Standard Class', 'Customer ID': 'SO-20335', 'Customer Name': \"Sean O'Donnell\", 'Segment': 'Consumer', 'Country': 'United States', 'City': 'Fort Lauderdale', 'State': 'Florida', 'Postal Code': '33311', 'Region': 'South', 'Product ID': 'FUR-TA-10000577', 'Category': 'Furniture', 'Sub-Category': 'Tables', 'Product Name': 'Bretford CR4500 Series Slim Rectangular Table', 'Sales': '957.5775', 'Quantity': '5', 'Discount': '0.45', 'Profit': '-383.031'}      |\n",
      "|{'Row ID': '5', 'Order ID': 'US-2015-108966', 'Order Date': '10/11/2015', 'Ship Date': '10/18/2015', 'Ship Mode': 'Standard Class', 'Customer ID': 'SO-20335', 'Customer Name': \"Sean O'Donnell\", 'Segment': 'Consumer', 'Country': 'United States', 'City': 'Fort Lauderdale', 'State': 'Florida', 'Postal Code': '33311', 'Region': 'South', 'Product ID': 'OFF-ST-10000760', 'Category': 'Office Supplies', 'Sub-Category': 'Storage', 'Product Name': \"Eldon Fold 'N Roll Cart System\", 'Sales': '22.368', 'Quantity': '2', 'Discount': '0.2', 'Profit': '2.5164'}                   |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "print(df_superstore.count())\n",
    "df_superstore.select(\"message\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aadd44cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "def parse_superstore(df):\n",
    "    superstore_schema = StructType([\n",
    "        StructField(\"Row ID\", StringType(), True),\n",
    "        StructField(\"Order ID\", StringType(), True),\n",
    "        StructField(\"Order Date\", StringType(), True),\n",
    "        StructField(\"Ship Date\", StringType(), True),\n",
    "        StructField(\"Ship Mode\", StringType(), True),\n",
    "        StructField(\"Customer ID\", StringType(), True),\n",
    "        StructField(\"Customer Name\", StringType(), True),\n",
    "        StructField(\"Segment\", StringType(), True),\n",
    "        StructField(\"Country\", StringType(), True),\n",
    "        StructField(\"City\", StringType(), True),\n",
    "        StructField(\"State\", StringType(), True),\n",
    "        StructField(\"Postal Code\", StringType(), True),\n",
    "        StructField(\"Region\", StringType(), True),\n",
    "        StructField(\"Product ID\", StringType(), True),\n",
    "        StructField(\"Category\", StringType(), True),\n",
    "        StructField(\"Sub-Category\", StringType(), True),\n",
    "        StructField(\"Product Name\", StringType(), True),\n",
    "        StructField(\"Sales\", StringType(), True),\n",
    "        StructField(\"Quantity\", StringType(), True),\n",
    "        StructField(\"Discount\", StringType(), True),\n",
    "        StructField(\"Profit\", StringType(), True)\n",
    "    ])\n",
    "    \n",
    "    parsed_superstore = df.select(\n",
    "        col(\"timestamp_kafka\"),\n",
    "        from_json(col(\"message\"), superstore_schema).alias(\"parsed_data\")\n",
    "    ).select(\n",
    "        col(\"timestamp_kafka\"),\n",
    "        col(\"parsed_data.Row ID\").cast(IntegerType()).alias(\"row_id\"),\n",
    "        col(\"parsed_data.Order ID\").alias(\"order_id\"),\n",
    "        to_date(col(\"parsed_data.Order Date\"), \"M/d/yyyy\").alias(\"order_date\"),\n",
    "        to_date(col(\"parsed_data.Ship Date\"), \"M/d/yyyy\").alias(\"ship_date\"),\n",
    "        col(\"parsed_data.Ship Mode\").alias(\"ship_mode\"),\n",
    "        col(\"parsed_data.Customer ID\").alias(\"customer_id\"),\n",
    "        col(\"parsed_data.Customer Name\").alias(\"customer_name\"),\n",
    "        col(\"parsed_data.Segment\").alias(\"segment\"),\n",
    "        col(\"parsed_data.Country\").alias(\"country\"),\n",
    "        col(\"parsed_data.City\").alias(\"city\"),\n",
    "        col(\"parsed_data.State\").alias(\"state\"),\n",
    "        col(\"parsed_data.Postal Code\").cast(IntegerType()).alias(\"postal_code\"),\n",
    "        col(\"parsed_data.Region\").alias(\"region\"),\n",
    "        col(\"parsed_data.Product ID\").alias(\"product_id\"),\n",
    "        col(\"parsed_data.Category\").alias(\"category\"),\n",
    "        col(\"parsed_data.Sub-Category\").alias(\"sub_category\"),\n",
    "        col(\"parsed_data.Product Name\").alias(\"product_name\"),\n",
    "        col(\"parsed_data.Sales\").cast(DecimalType(10,2)).alias(\"sales\"),\n",
    "        col(\"parsed_data.Quantity\").cast(IntegerType()).alias(\"quantity\"),\n",
    "        col(\"parsed_data.Discount\").cast(DecimalType(5,4)).alias(\"discount\"),\n",
    "        col(\"parsed_data.Profit\").cast(DecimalType(10,2)).alias(\"profit\")\n",
    "    )\n",
    "    \n",
    "    return parsed_superstore\n",
    "df_parsed_superstore = parse_superstore(df_superstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd647dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "['timestamp_kafka', 'row_id', 'order_id', 'order_date', 'ship_date', 'ship_mode', 'customer_id', 'customer_name', 'segment', 'country', 'city', 'state', 'postal_code', 'region', 'product_id', 'category', 'sub_category', 'product_name', 'sales', 'quantity', 'discount', 'profit'] \n",
      "\n",
      "+--------------------+------+--------------+----------+----------+--------------+-----------+---------------+---------+-------------+---------------+----------+-----------+------+---------------+---------------+------------+--------------------+------+--------+--------+-------+\n",
      "|     timestamp_kafka|row_id|      order_id|order_date| ship_date|     ship_mode|customer_id|  customer_name|  segment|      country|           city|     state|postal_code|region|     product_id|       category|sub_category|        product_name| sales|quantity|discount| profit|\n",
      "+--------------------+------+--------------+----------+----------+--------------+-----------+---------------+---------+-------------+---------------+----------+-----------+------+---------------+---------------+------------+--------------------+------+--------+--------+-------+\n",
      "|2025-06-26 15:42:...|     1|CA-2016-152156|2016-11-08|2016-11-11|  Second Class|   CG-12520|    Claire Gute| Consumer|United States|      Henderson|  Kentucky|      42420| South|FUR-BO-10001798|      Furniture|   Bookcases|Bush Somerset Col...|261.96|       2|  0.0000|  41.91|\n",
      "|2025-06-26 15:42:...|     2|CA-2016-152156|2016-11-08|2016-11-11|  Second Class|   CG-12520|    Claire Gute| Consumer|United States|      Henderson|  Kentucky|      42420| South|FUR-CH-10000454|      Furniture|      Chairs|Hon Deluxe Fabric...|731.94|       3|  0.0000| 219.58|\n",
      "|2025-06-26 15:42:...|     3|CA-2016-138688|2016-06-12|2016-06-16|  Second Class|   DV-13045|Darrin Van Huff|Corporate|United States|    Los Angeles|California|      90036|  West|OFF-LA-10000240|Office Supplies|      Labels|Self-Adhesive Add...| 14.62|       2|  0.0000|   6.87|\n",
      "|2025-06-26 15:42:...|     4|US-2015-108966|2015-10-11|2015-10-18|Standard Class|   SO-20335| Sean O'Donnell| Consumer|United States|Fort Lauderdale|   Florida|      33311| South|FUR-TA-10000577|      Furniture|      Tables|Bretford CR4500 S...|957.58|       5|  0.4500|-383.03|\n",
      "|2025-06-26 15:42:...|     5|US-2015-108966|2015-10-11|2015-10-18|Standard Class|   SO-20335| Sean O'Donnell| Consumer|United States|Fort Lauderdale|   Florida|      33311| South|OFF-ST-10000760|Office Supplies|     Storage|Eldon Fold 'N Rol...| 22.37|       2|  0.2000|   2.52|\n",
      "+--------------------+------+--------------+----------+----------+--------------+-----------+---------------+---------+-------------+---------------+----------+-----------+------+---------------+---------------+------------+--------------------+------+--------+--------+-------+\n",
      "only showing top 5 rows\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(len(df_parsed_superstore.columns))\n",
    "print(f\"{(df_parsed_superstore.columns)} \\n\")\n",
    "print(df_parsed_superstore.show(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1575f2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------+----------+----------+--------------+-----------+----------------+--------+-------------+-----------+----------+-----------+------+---------------+---------------+------------+--------------------+------+--------+--------+------+\n",
      "|     timestamp_kafka|row_id|      order_id|order_date| ship_date|     ship_mode|customer_id|   customer_name| segment|      country|       city|     state|postal_code|region|     product_id|       category|sub_category|        product_name| sales|quantity|discount|profit|\n",
      "+--------------------+------+--------------+----------+----------+--------------+-----------+----------------+--------+-------------+-----------+----------+-----------+------+---------------+---------------+------------+--------------------+------+--------+--------+------+\n",
      "|2025-06-26 15:46:...|  9994|CA-2017-119914|2017-05-04|2017-05-09|  Second Class|   CC-12220|    Chris Cortes|Consumer|United States|Westminster|California|      92683|  West|OFF-AP-10002684|Office Supplies|  Appliances|Acco 7-Outlet Mas...|243.16|       2|  0.0000| 72.95|\n",
      "|2025-06-26 15:46:...|  9993|CA-2017-121258|2017-02-26|2017-03-03|Standard Class|   DB-13060|     Dave Brooks|Consumer|United States| Costa Mesa|California|      92627|  West|OFF-PA-10004041|Office Supplies|       Paper|It's Hot Message ...| 29.60|       4|  0.0000| 13.32|\n",
      "|2025-06-26 15:46:...|  9992|CA-2017-121258|2017-02-26|2017-03-03|Standard Class|   DB-13060|     Dave Brooks|Consumer|United States| Costa Mesa|California|      92627|  West|TEC-PH-10003645|     Technology|      Phones|Aastra 57i VoIP p...|258.58|       2|  0.2000| 19.39|\n",
      "|2025-06-26 15:46:...|  9991|CA-2017-121258|2017-02-26|2017-03-03|Standard Class|   DB-13060|     Dave Brooks|Consumer|United States| Costa Mesa|California|      92627|  West|FUR-FU-10000747|      Furniture| Furnishings|Tenex B1-RE Serie...| 91.96|       2|  0.0000| 15.63|\n",
      "|2025-06-26 15:46:...|  9990|CA-2014-110422|2014-01-21|2014-01-23|  Second Class|   TB-21400|Tom Boeckenhauer|Consumer|United States|      Miami|   Florida|      33180| South|FUR-FU-10001889|      Furniture| Furnishings|Ultra Door Pull H...| 25.25|       3|  0.2000|  4.10|\n",
      "+--------------------+------+--------------+----------+----------+--------------+-----------+----------------+--------+-------------+-----------+----------+-----------+------+---------------+---------------+------------+--------------------+------+--------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_parsed_superstore.orderBy(col(\"row_id\").desc()).limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede6d685",
   "metadata": {},
   "source": [
    "Check Null Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d26e6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+------+--------+----------+---------+---------+-----------+-------------+-------+-------+----+-----+-----------+------+----------+--------+------------+------------+-----+--------+--------+------+\n",
      "|timestamp_kafka        |row_id|order_id|order_date|ship_date|ship_mode|customer_id|customer_name|segment|country|city|state|postal_code|region|product_id|category|sub_category|product_name|sales|quantity|discount|profit|\n",
      "+-----------------------+------+--------+----------+---------+---------+-----------+-------------+-------+-------+----+-----+-----------+------+----------+--------+------------+------------+-----+--------+--------+------+\n",
      "|2025-06-26 15:42:39.472|NULL  |NULL    |NULL      |NULL     |NULL     |NULL       |NULL         |NULL   |NULL   |NULL|NULL |NULL       |NULL  |NULL      |NULL    |NULL        |NULL        |NULL |NULL    |NULL    |NULL  |\n",
      "|2025-06-26 15:42:39.473|NULL  |NULL    |NULL      |NULL     |NULL     |NULL       |NULL         |NULL   |NULL   |NULL|NULL |NULL       |NULL  |NULL      |NULL    |NULL        |NULL        |NULL |NULL    |NULL    |NULL  |\n",
      "|2025-06-26 15:42:39.479|NULL  |NULL    |NULL      |NULL     |NULL     |NULL       |NULL         |NULL   |NULL   |NULL|NULL |NULL       |NULL  |NULL      |NULL    |NULL        |NULL        |NULL |NULL    |NULL    |NULL  |\n",
      "|2025-06-26 15:42:39.479|NULL  |NULL    |NULL      |NULL     |NULL     |NULL       |NULL         |NULL   |NULL   |NULL|NULL |NULL       |NULL  |NULL      |NULL    |NULL        |NULL        |NULL |NULL    |NULL    |NULL  |\n",
      "|2025-06-26 15:42:39.485|NULL  |NULL    |NULL      |NULL     |NULL     |NULL       |NULL         |NULL   |NULL   |NULL|NULL |NULL       |NULL  |NULL      |NULL    |NULL        |NULL        |NULL |NULL    |NULL    |NULL  |\n",
      "|2025-06-26 15:42:39.486|NULL  |NULL    |NULL      |NULL     |NULL     |NULL       |NULL         |NULL   |NULL   |NULL|NULL |NULL       |NULL  |NULL      |NULL    |NULL        |NULL        |NULL |NULL    |NULL    |NULL  |\n",
      "|2025-06-26 15:42:39.493|NULL  |NULL    |NULL      |NULL     |NULL     |NULL       |NULL         |NULL   |NULL   |NULL|NULL |NULL       |NULL  |NULL      |NULL    |NULL        |NULL        |NULL |NULL    |NULL    |NULL  |\n",
      "|2025-06-26 15:42:39.493|NULL  |NULL    |NULL      |NULL     |NULL     |NULL       |NULL         |NULL   |NULL   |NULL|NULL |NULL       |NULL  |NULL      |NULL    |NULL        |NULL        |NULL |NULL    |NULL    |NULL  |\n",
      "|2025-06-26 15:42:39.494|NULL  |NULL    |NULL      |NULL     |NULL     |NULL       |NULL         |NULL   |NULL   |NULL|NULL |NULL       |NULL  |NULL      |NULL    |NULL        |NULL        |NULL |NULL    |NULL    |NULL  |\n",
      "|2025-06-26 15:42:39.498|NULL  |NULL    |NULL      |NULL     |NULL     |NULL       |NULL         |NULL   |NULL   |NULL|NULL |NULL       |NULL  |NULL      |NULL    |NULL        |NULL        |NULL |NULL    |NULL    |NULL  |\n",
      "+-----------------------+------+--------+----------+---------+---------+-----------+-------------+-------+-------+----+-----+-----------+------+----------+--------+------------+------------+-----+--------+--------+------+\n",
      "only showing top 10 rows\n",
      "Total null: 268\n"
     ]
    }
   ],
   "source": [
    "all_null_rows = df_parsed_superstore.filter(\n",
    "    col(\"row_id\").isNull() & \n",
    "    col(\"order_id\").isNull() & \n",
    "    col(\"customer_name\").isNull()\n",
    ")\n",
    "all_null_rows.show(10, truncate=False)\n",
    "print(f\"Total null: {all_null_rows.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72b8ac46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9668\n"
     ]
    }
   ],
   "source": [
    "df_parsed_superstore=df_parsed_superstore.dropna()\n",
    "print(df_parsed_superstore.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f406ac",
   "metadata": {},
   "source": [
    "Check Data Anomali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07722eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "negative_sales = df_parsed_superstore.filter(col(\"sales\") < 0).count()\n",
    "negative_quantity = df_parsed_superstore.filter(col(\"quantity\") < 0).count()\n",
    "negative_discount = df_parsed_superstore.filter(col(\"discount\") < 0).count()\n",
    "print (negative_sales, negative_quantity , negative_discount)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b99791",
   "metadata": {},
   "source": [
    "Check Duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b259b09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: 9668\n",
      "Distinct data: 9668\n",
      "Duplicate data: 0\n"
     ]
    }
   ],
   "source": [
    "total_data = df_parsed_superstore.count()\n",
    "distinct_data = df_parsed_superstore.distinct().count()\n",
    "duplicate_data = total_data - distinct_data\n",
    "\n",
    "print(f\"Total data: {total_data}\")\n",
    "print(f\"Distinct data: {distinct_data}\")\n",
    "print(f\"Duplicate data: {duplicate_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9e76e2",
   "metadata": {},
   "source": [
    "Create DW Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7922175a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS db_tgp2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "488f89ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"USE db_tgp2\")\n",
    "\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS dim_date (date_id INT, date DATE, month INT, year INT) USING hive\")\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS dim_ship (ship_id INT, ship_mode STRING) USING hive\")\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS dim_city (city_id INT, city_name STRING) USING hive\")\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS dim_customer (customer_id INT, customer_name STRING, zipcode STRING) USING hive\")\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS dim_state (state_id INT, state_name STRING) USING hive\")\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS dim_segment (segment_id INT, segment STRING) USING hive\")\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS dim_region (region_id INT, region STRING) USING hive\")\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS dim_product (product_id INT, product_name STRING) USING hive\")\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS dim_product_category (category_id INT, product_category STRING) USING hive\")\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS dim_product_subcategory (subcategory_id INT, product_subcategory STRING) USING hive\")\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS order_fact (order_id INT, sales DECIMAL(10,2), quantity INT, profits DECIMAL(10,2), discount DECIMAL(5,2)) USING hive\")\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS dim_product_hierarchy (product_id INT,category_id INT,subcategory_id INT) USING hive\")\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS dim_order (order_id INT,product_id INT,customer_id INT,ship_mode_id INT,order_date_id INT,shipment_date_id INT) USING hive\")\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS dim_customer_location (customer_id INT, city_id INT, state_id INT, segment_id INT, region_id INT) USING hive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100488d6",
   "metadata": {},
   "source": [
    "Send to Hive (Data Warehouse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa08fc79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
