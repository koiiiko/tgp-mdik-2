{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30fcebf5",
   "metadata": {},
   "source": [
    "Activate Kafka-HDFS Connectore using Apache Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93dc47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyspark==4.0.0\n",
    "# !pip install delta-spark==4.0.0\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "# import os\n",
    "# os.environ[\"JAVA_HOME\"] = \"C:/Program Files/Java/jdk-17.0.2/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf8d7ba",
   "metadata": {},
   "source": [
    "Buat Session Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa32b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkatoHDFS\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.13:4.0.0\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"SparkSession build\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69339bc6",
   "metadata": {},
   "source": [
    "PIndahkan data dari Kafka ke HDFS (Data Superstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1e0c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pilih topic yang akan disimpan di storage layer (HDFS)\n",
    "\n",
    "df = spark.read\\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "    .option(\"subscribe\", \"twcs\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .option(\"endingOffsets\", \"latest\") \\\n",
    "    .load()\n",
    "\n",
    "df_superstore = df.select(col(\"value\").cast(\"string\").alias(\"message\"), col(\"timestamp\").alias(\"timestamp_kafka\"))\n",
    "df_superstore.write.mode(\"overwrite\").format(\"parquet\").save(\"hdfs://localhost:9000/hdfs_twcs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27332646",
   "metadata": {},
   "source": [
    "Cek Hasil di HDFS (Data Superstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f76f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkcheck = SparkSession.builder.appName(\"Cek output HDFS\").getOrCreate()\n",
    "\n",
    "df2 = sparkcheck.read.parquet(\"hdfs://localhost:9000/hdfs_twcs\")\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c40b39",
   "metadata": {},
   "source": [
    "Buat Session Spark untuk DeltaSpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f4b7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkDelta = SparkSession.builder \\\n",
    "    .appName(\"DeltaLake\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.jars.packages\", \n",
    "            \"org.apache.spark:spark-sql-kafka-0-10_2.13:4.0.0,io.delta:delta-spark_2.13:4.0.0\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"DeltaSparkSession build\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c53d8c",
   "metadata": {},
   "source": [
    "Pindah format dari dari HDFS (parquet) menjadi format standar data lakehouse (Delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e222c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = sparkDelta.read.parquet(\"hdfs://localhost:9000/hdfs_superstore\")\n",
    "df2.write.format(\"delta\").mode(\"overwrite\").save(\"hdfs://localhost:9000/delta_superstore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c3611d",
   "metadata": {},
   "source": [
    "Cek hasilnya di Delta Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd055410",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delta = sparkDelta.read.format(\"delta\").load(\"hdfs://localhost:9000/delta_superstore\")\n",
    "df_delta.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6651e20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delta.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24be7715",
   "metadata": {},
   "source": [
    "Data Properties check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6bbd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkDelta.sql(\"DESCRIBE DETAIL delta.`hdfs://localhost:9000/delta_superstore`\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe8d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkDelta.sql(\"DESCRIBE HISTORY delta.`hdfs://localhost:9000/delta_superstore`\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
